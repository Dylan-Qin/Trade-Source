---
layout: post
categories: paper
title: "RiskAnalysis andRiskManagementfor the Artificial Superintelligence Research and Development Process"
author: "Anthony Barrett"
date: 2016-07-15
tags: ['risk analysis', ' risk management', ' artificial intelligence']
---

Artificial superintelligence (ASI) is increasingly recognized as a significant future risk. In the absence of adequate safety mechanisms, an ASI may even be likely to cause human extinction. Thus ASI risk scenarios merit attention even if their probabilities are low. ASI risk can be addressed in at least two ways: by building safety mechanisms into the ASI itself, as in ASI safety research, and by managing the human process of developing ASI, in order to promote safety practices in ASI research and development (R&D). While ASI researchers and developers typically do not intend to cause harm through their work, harm may nonetheless occur due to accidents and unintended consequences. Thus opportunities may exist to reduce ASI risk through engagement with the R&D process. This paper surveys established methodologies for risk analysis and risk management, emphasizing fault trees and event trees, and describes how these techniques can be applied to risk from ASI R&D. A variety of risk methodologies have been developed for other risks, including other emerging technology risks, but their application to ASI has thus far been limited. Insights from risk literatures could improve on what existing analyses of ASI risk have yet been conducted. Likewise, a more thorough and rigorous analysis of ASI R&D processes can inform decision making to reduce the risk. The decision makers include governments and non-governmental organizations active in ASI oversight, as well anyone conducting ASI R&D. All of these individuals and groups have roles to play in addressing ASI risk.

人工超级智能（ASI）日益被视为未来的一项重大风险。在缺乏足够安全机制的情况下，ASI甚至可能导致人类灭绝。因此即便发生概率较低，ASI风险情景仍值得关注。应对ASI风险至少存在两种途径：一是在ASI内部构建安全机制（如ASI安全研究领域所做的那样），二是通过管理人类开发ASI的进程来促进其研发过程中的安全实践。尽管ASI研究者与开发者通常无意通过其工作造成伤害，但事故和意外后果仍可能导致危害发生。因此通过介入研发流程来降低ASI风险存在可行性。本文梳理了风险分析与风险管理的成熟方法论（重点包括故障树与事件树），并阐述如何将这些技术应用于ASI研发风险。针对其他风险（包括其他新兴技术风险）已发展出多种风险分析方法，但迄今在ASI领域的应用仍有限。来自风险研究文献的洞见可改进现有ASI风险分析的不足。同样，对ASI研发流程进行更全面严谨的分析，能为降低风险的决策提供依据。这些决策者包括积极参与ASI监管的政府与非政府组织，以及所有从事ASI研发的实体。所有这些个体与群体在应对ASI风险中都扮演着重要角色。

资源链接: [RiskAnalysis andRiskManagementfor the Artificial Superintelligence Research and Development Process](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=2807358)
